{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweets about eating disorders\n",
    "## Modelling with CV\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import re, string, unicodedata\n",
    "import nltk\n",
    "from nltk import word_tokenize, sent_tokenize, FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import LancasterStemmer, WordNetLemmatizer\n",
    "nltk.download\n",
    "from ast import literal_eval\n",
    "'''\n",
    "tweets = pd.read_csv('ed-dataset-falcon_spacy2-embeddings-sentence.csv', sep=';', encoding='utf8', converters=\n",
    "                           {\n",
    "                            'entities_instances_wikidata':literal_eval,\n",
    "                            'spacy_entities_ids':literal_eval,\n",
    "                            'spacy_entities_labels':literal_eval,\n",
    "                            'falcon_spacy_entities':literal_eval,\n",
    "                            'falcon_spacy_labels':literal_eval,\n",
    "                            'falcon_spacy_embeddingsmd4_mw50_RW':literal_eval,\n",
    "                            'falcon_spacy_embeddingsmd2_mw100_RW':literal_eval,\n",
    "                            'sent_embedding_1':literal_eval,\n",
    "                            'sent_embedding_2':literal_eval},error_bad_lines=False)\n",
    "\n",
    "'''\n",
    "tweets = pd.read_csv('ed-dataset-falcon_spacy2-embeddings-sentence-md4.csv', sep=';', encoding='utf8', converters=\n",
    "                           {\n",
    "                            'falcon_spacy_embeddingsmd4_mw50_RW':literal_eval,\n",
    "                            'sent_embedding_1':literal_eval},error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import nltk\n",
    "import nltk.data\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "import regex as re\n",
    "import string\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from simpletransformers.classification import ClassificationModel\n",
    "import io\n",
    "\n",
    "punctuations = \"¡!#$%&'()*+,-./:;<=>¿?@[\\]^_`{|}~\"\n",
    "def read_txt(filename):\n",
    "    list = []\n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        data = f.readlines()\n",
    "        for line in data:\n",
    "            list.append(str(line).replace('\\n', ''))\n",
    "    return list\n",
    "\n",
    "stopwords = read_txt('english_stopwords.txt')\n",
    "stemmer = SnowballStemmer('english')\n",
    "def clean_accents(tweet):\n",
    "    tweet = re.sub(r\"[àáâãäå]\", \"a\", tweet)\n",
    "    tweet = re.sub(r\"ç\", \"c\", tweet)\n",
    "    tweet = re.sub(r\"[èéêë]\", \"e\", tweet)\n",
    "    tweet = re.sub(r\"[ìíîï]\", \"i\", tweet)\n",
    "    tweet = re.sub(r\"[òóôõö]\", \"o\", tweet)\n",
    "    tweet = re.sub(r\"[ùúûü]\", \"u\", tweet)\n",
    "    tweet = re.sub(r\"[ýÿ]\", \"y\", tweet)\n",
    "\n",
    "    return tweet\n",
    "\n",
    "def clean_tweet(tweet, stem = False):\n",
    "    tweet = tweet.lower().strip()\n",
    "    tweet = re.sub(r'https?:\\/\\/\\S+', '', tweet)\n",
    "    tweet = re.sub(r'http?:\\/\\/\\S+', '', tweet)\n",
    "    tweet = re.sub(r'www?:\\/\\/\\S+', '', tweet)\n",
    "    tweet = re.sub(r'\\s([@#][\\w_-]+)', \"\", tweet)\n",
    "    tweet = re.sub(r\"\\n\", \" \", tweet)\n",
    "    tweet = clean_accents(tweet)\n",
    "    tweet = re.sub(r\"\\b(a*ha+h[ha]*|o?l+o+l+[ol]*|x+d+[x*d*]*|a*ja+[j+a+]+)\\b\", \"<risas>\", tweet)\n",
    "    for symbol in punctuations:\n",
    "        tweet = tweet.replace(symbol, \"\")\n",
    "    tokens = []\n",
    "    for token in tweet.strip().split():\n",
    "        if token not in punctuations and token not in stopwords:\n",
    "            if stem:\n",
    "                tokens.append(stemmer.stem(token))\n",
    "            else:\n",
    "                tokens.append(token)\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \tid\ttext_orig\tED_Patient\tProED\tinformative\tscientific\thashtags\t\n",
    "# entities_instances_wikidata\tspacy_entities_ids\tspacy_entities_labels\t\n",
    "# falcon_spacy_entities\tfalcon_spacy_labels\tfalcon_spacy_embeddingsmd2_mw50_RW\t\n",
    "# falcon_spacy_embeddingsmd2_mw100_RW\tsent_embedding_1\tsent_embedding_2\n",
    "\n",
    "cols = ['id','text_orig','ED_Patient','ProED','informative','scientific','hashtag','entities_instances_wikidata','spacy_entities_ids','spacy_entities_labels','falcon_spacy_entities'\n",
    "       ,'falcon_spacy_labels','falcon_spacy_embeddingsmd2_mw50_RW','falcon_spacy_embeddingsmd2_mw100_RW','sent_embedding_1','sent_embedding_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets1 = tweets.copy()\n",
    "# .drop(['entities_instances_wikidata','spacy_entities_ids','spacy_entities_labels'], axis=1)\n",
    "\n",
    "tweets1['text_cleaned'] = tweets['text_orig'].apply(lambda s : clean_tweet(s))\n",
    "#print(tweets1['text_cleaned'].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweets1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\MICROSOFT\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.datasets import load_files\n",
    "nltk.download('stopwords')\n",
    "import pickle\n",
    "from nltk.corpus import stopwords\n",
    "df = tweets1.copy()\n",
    "X = df['text_cleaned']\n",
    "X_b = np.array(df['sent_embedding_1'].tolist())\n",
    "X_b = np.asarray(X_b, dtype=np.float32)\n",
    "\n",
    "\n",
    "#X = np.array(df['falcon_spacy_labels'].tolist())\n",
    "\n",
    "Y1 = df['ED_Patient']\n",
    "Y2 = df['ProED']\n",
    "Y3 = df['informative']\n",
    "Y4 = df['scientific']\n",
    "\n",
    "documents = []\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "stemmer = WordNetLemmatizer()\n",
    "\n",
    "for sen in range(0, len(X)):\n",
    "    # Remove all the special characters\n",
    "    document = re.sub(r'\\W', ' ', str(X[sen]))\n",
    "    \n",
    "    # remove all single characters\n",
    "    document = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', document)\n",
    "    \n",
    "    # Remove single characters from the start\n",
    "    document = re.sub(r'\\^[a-zA-Z]\\s+', ' ', document) \n",
    "    \n",
    "    # Substituting multiple spaces with single space\n",
    "    document = re.sub(r'\\s+', ' ', document, flags=re.I)\n",
    "    \n",
    "    # Removing prefixed 'b'\n",
    "    document = re.sub(r'^b\\s+', '', document)\n",
    "    \n",
    "    # Converting to Lowercase\n",
    "    document = document.lower()\n",
    "    \n",
    "    # Lemmatization\n",
    "    document = document.split()\n",
    "\n",
    "    document = [stemmer.lemmatize(word) for word in document]\n",
    "    document = ' '.join(document)\n",
    "    \n",
    "    documents.append(document)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(max_features=1500, min_df=5, max_df=0.7, stop_words=stopwords.words('english'))\n",
    "X = vectorizer.fit_transform(documents).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(max_features=1500, min_df=5, max_df=0.7, stop_words=stopwords.words('english'))\n",
    "X = vectorizer.fit_transform(documents).toarray()\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidfconverter = TfidfTransformer()\n",
    "X = tfidfconverter.fit_transform(X).toarray()\n",
    "\n",
    "Xc = np.zeros((1968,1222))\n",
    "for i in range(1968):\n",
    "    Xc[i] = np.concatenate((X[i],X_b[i]))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[253  42]\n",
      " [ 41 255]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86       295\n",
      "           1       0.86      0.86      0.86       296\n",
      "\n",
      "    accuracy                           0.86       591\n",
      "   macro avg       0.86      0.86      0.86       591\n",
      "weighted avg       0.86      0.86      0.86       591\n",
      "\n",
      "0.8595600676818951\n",
      "[[268  27]\n",
      " [ 92 204]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.91      0.82       295\n",
      "           1       0.88      0.69      0.77       296\n",
      "\n",
      "    accuracy                           0.80       591\n",
      "   macro avg       0.81      0.80      0.80       591\n",
      "weighted avg       0.81      0.80      0.80       591\n",
      "\n",
      "0.7986463620981388\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(Xc, Y1, test_size=0.3, random_state=42)\n",
    "classifier = RandomForestClassifier(n_estimators=1000, random_state=0)\n",
    "classifier.fit(X1_train, y1_train) \n",
    "\n",
    "y1_pred = classifier.predict(X1_test)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(confusion_matrix(y1_test,y1_pred))\n",
    "print(classification_report(y1_test,y1_pred))\n",
    "print(accuracy_score(y1_test, y1_pred))\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X, Y1, test_size=0.3, random_state=42)\n",
    "classifier = RandomForestClassifier(n_estimators=1000, random_state=0)\n",
    "classifier.fit(X1_train, y1_train) \n",
    "\n",
    "y1_pred = classifier.predict(X1_test)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(confusion_matrix(y1_test,y1_pred))\n",
    "print(classification_report(y1_test,y1_pred))\n",
    "print(accuracy_score(y1_test, y1_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[455  10]\n",
      " [ 62  64]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.98      0.93       465\n",
      "           1       0.86      0.51      0.64       126\n",
      "\n",
      "    accuracy                           0.88       591\n",
      "   macro avg       0.87      0.74      0.78       591\n",
      "weighted avg       0.88      0.88      0.87       591\n",
      "\n",
      "0.8781725888324873\n",
      "[[421  44]\n",
      " [ 39  87]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.91       465\n",
      "           1       0.66      0.69      0.68       126\n",
      "\n",
      "    accuracy                           0.86       591\n",
      "   macro avg       0.79      0.80      0.79       591\n",
      "weighted avg       0.86      0.86      0.86       591\n",
      "\n",
      "0.8595600676818951\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(Xc, Y2, test_size=0.3, random_state=42)\n",
    "classifier = RandomForestClassifier(n_estimators=1000, random_state=0)\n",
    "classifier.fit(X1_train, y1_train) \n",
    "\n",
    "y1_pred = classifier.predict(X1_test)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(confusion_matrix(y1_test,y1_pred))\n",
    "print(classification_report(y1_test,y1_pred))\n",
    "print(accuracy_score(y1_test, y1_pred))\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X, Y2, test_size=0.3, random_state=42)\n",
    "classifier = RandomForestClassifier(n_estimators=1000, random_state=0)\n",
    "classifier.fit(X1_train, y1_train) \n",
    "\n",
    "y1_pred = classifier.predict(X1_test)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(confusion_matrix(y1_test,y1_pred))\n",
    "print(classification_report(y1_test,y1_pred))\n",
    "print(accuracy_score(y1_test, y1_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[322  34]\n",
      " [ 59 176]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.87       356\n",
      "           1       0.84      0.75      0.79       235\n",
      "\n",
      "    accuracy                           0.84       591\n",
      "   macro avg       0.84      0.83      0.83       591\n",
      "weighted avg       0.84      0.84      0.84       591\n",
      "\n",
      "0.8426395939086294\n",
      "[[332  24]\n",
      " [101 134]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.93      0.84       356\n",
      "           1       0.85      0.57      0.68       235\n",
      "\n",
      "    accuracy                           0.79       591\n",
      "   macro avg       0.81      0.75      0.76       591\n",
      "weighted avg       0.80      0.79      0.78       591\n",
      "\n",
      "0.7884940778341794\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(Xc, Y3, test_size=0.3, random_state=42)\n",
    "classifier = RandomForestClassifier(n_estimators=1000, random_state=0)\n",
    "classifier.fit(X1_train, y1_train) \n",
    "\n",
    "y1_pred = classifier.predict(X1_test)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(confusion_matrix(y1_test,y1_pred))\n",
    "print(classification_report(y1_test,y1_pred))\n",
    "print(accuracy_score(y1_test, y1_pred))\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X, Y3, test_size=0.3, random_state=42)\n",
    "classifier = RandomForestClassifier(n_estimators=1000, random_state=0)\n",
    "classifier.fit(X1_train, y1_train) \n",
    "\n",
    "y1_pred = classifier.predict(X1_test)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(confusion_matrix(y1_test,y1_pred))\n",
    "print(classification_report(y1_test,y1_pred))\n",
    "print(accuracy_score(y1_test, y1_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[419  18]\n",
      " [ 26 128]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95       437\n",
      "           1       0.88      0.83      0.85       154\n",
      "\n",
      "    accuracy                           0.93       591\n",
      "   macro avg       0.91      0.89      0.90       591\n",
      "weighted avg       0.92      0.93      0.92       591\n",
      "\n",
      "0.9255499153976311\n",
      "[[433   4]\n",
      " [ 70  84]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.99      0.92       437\n",
      "           1       0.95      0.55      0.69       154\n",
      "\n",
      "    accuracy                           0.87       591\n",
      "   macro avg       0.91      0.77      0.81       591\n",
      "weighted avg       0.89      0.87      0.86       591\n",
      "\n",
      "0.8747884940778342\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(Xc, Y4, test_size=0.3, random_state=42)\n",
    "classifier = RandomForestClassifier(n_estimators=1000, random_state=0)\n",
    "classifier.fit(X1_train, y1_train) \n",
    "\n",
    "y1_pred = classifier.predict(X1_test)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(confusion_matrix(y1_test,y1_pred))\n",
    "print(classification_report(y1_test,y1_pred))\n",
    "print(accuracy_score(y1_test, y1_pred))\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X, Y4, test_size=0.3, random_state=42)\n",
    "classifier = RandomForestClassifier(n_estimators=1000, random_state=0)\n",
    "classifier.fit(X1_train, y1_train) \n",
    "\n",
    "y1_pred = classifier.predict(X1_test)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(confusion_matrix(y1_test,y1_pred))\n",
    "print(classification_report(y1_test,y1_pred))\n",
    "print(accuracy_score(y1_test, y1_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Model\n",
    "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = tweets1.copy()\n",
    "\n",
    "X_orig = df['text_cleaned']\n",
    "X_b = np.array(df['sent_embedding_1'].tolist())\n",
    "X_b = np.asarray(X_b, dtype=np.float32)\n",
    "\n",
    "Y1 = df['ED_Patient']\n",
    "Y2 = df['ProED']\n",
    "Y3 = df['informative']\n",
    "Y4 = df['scientific']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 1000\n",
    "max_len = 100\n",
    "tok = Tokenizer(num_words=max_words)\n",
    "tok.fit_on_texts(X_orig)\n",
    "sequences = tok.texts_to_sequences(X_orig)\n",
    "X_c = sequence.pad_sequences(sequences,maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1968, 100)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1968, 100)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_b + X_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len=1000\n",
    "def RNN():\n",
    "    inputs = Input(name='inputs',shape=[max_len])\n",
    "    layer = Embedding(max_words,100,input_length=max_len)(inputs)\n",
    "    layer = LSTM(100)(layer)\n",
    "    layer = Dense(256,name='FC1')(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    layer = Dropout(0.1)(layer)\n",
    "    layer = Dense(1,name='out_layer')(layer)\n",
    "    layer = Activation('sigmoid')(layer)\n",
    "    model = Model(inputs=inputs,outputs=layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "'''y1_pred = model.predict(X1_test)\n",
    "y1_pred = np.argmax(y1_pred, axis=1)\n",
    "conf_mat = confusion_matrix(y1_test, y1_pred)'''\n",
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          [(None, 200)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_4 (Embedding)      (None, 200, 100)          100000    \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 256)               25856     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 206,513\n",
      "Trainable params: 206,513\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 200) for input Tensor(\"inputs_4:0\", shape=(None, 200), dtype=float32), but it was called on an input with incompatible shape (None, 100).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 200) for input Tensor(\"inputs_4:0\", shape=(None, 200), dtype=float32), but it was called on an input with incompatible shape (None, 100).\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6835 - acc: 0.5514 - f1_m: 0.3259 - precision_m: 0.5317 - recall_m: 0.3154WARNING:tensorflow:Model was constructed with shape (None, 200) for input Tensor(\"inputs_4:0\", shape=(None, 200), dtype=float32), but it was called on an input with incompatible shape (None, 100).\n",
      "8/8 [==============================] - 1s 132ms/step - loss: 0.6835 - acc: 0.5514 - f1_m: 0.3259 - precision_m: 0.5317 - recall_m: 0.3154 - val_loss: 0.6787 - val_acc: 0.5290 - val_f1_m: 0.6596 - val_precision_m: 0.5029 - val_recall_m: 0.9607\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.5729 - acc: 0.7269 - f1_m: 0.7176 - precision_m: 0.7626 - recall_m: 0.7447 - val_loss: 0.5392 - val_acc: 0.7319 - val_f1_m: 0.7096 - val_precision_m: 0.6810 - val_recall_m: 0.7415\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.4124 - acc: 0.8235 - f1_m: 0.8189 - precision_m: 0.7954 - recall_m: 0.8526 - val_loss: 0.5433 - val_acc: 0.7271 - val_f1_m: 0.6777 - val_precision_m: 0.7879 - val_recall_m: 0.5971\n",
      "Test set\n",
      "  Loss: 0.497\n",
      "  Accuracy: 0.770\n",
      " fº 0.722\n",
      "Model: \"functional_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          [(None, 200)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_5 (Embedding)      (None, 200, 100)          100000    \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 256)               25856     \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 206,513\n",
      "Trainable params: 206,513\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "8/8 [==============================] - 2s 211ms/step - loss: 0.6702 - acc: 0.6293 - f1_m: 0.5047 - precision_m: 0.7526 - recall_m: 0.4976 - val_loss: 0.5976 - val_acc: 0.6691 - val_f1_m: 0.5017 - val_precision_m: 0.8870 - val_recall_m: 0.3503\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 1s 161ms/step - loss: 0.4752 - acc: 0.8058 - f1_m: 0.7862 - precision_m: 0.8542 - recall_m: 0.7507 - val_loss: 0.4622 - val_acc: 0.7705 - val_f1_m: 0.7699 - val_precision_m: 0.6854 - val_recall_m: 0.8789\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 1s 166ms/step - loss: 0.3270 - acc: 0.8754 - f1_m: 0.8752 - precision_m: 0.8632 - recall_m: 0.8919 - val_loss: 0.4119 - val_acc: 0.8116 - val_f1_m: 0.7851 - val_precision_m: 0.7599 - val_recall_m: 0.8193\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 1s 165ms/step - loss: 0.2573 - acc: 0.8858 - f1_m: 0.8845 - precision_m: 0.8770 - recall_m: 0.8984 - val_loss: 0.4354 - val_acc: 0.7995 - val_f1_m: 0.7474 - val_precision_m: 0.7436 - val_recall_m: 0.7533\n",
      "Test set\n",
      "  Loss: 0.333\n",
      "  Accuracy: 0.854\n",
      " fº 0.853\n"
     ]
    }
   ],
   "source": [
    "# CATEGORY 1\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X_orig, Y1, test_size=0.3, random_state=42)\n",
    "\n",
    "max_words = 1000\n",
    "max_len = 200\n",
    "tok = Tokenizer(num_words=max_words)\n",
    "tok.fit_on_texts(X1_train)\n",
    "sequences = tok.texts_to_sequences(X1_train)\n",
    "sequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len)\n",
    "model = RNN()\n",
    "model.summary()\n",
    "model.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['acc',f1_m,precision_m, recall_m])\n",
    "model.fit(sequences_matrix,y1_train,batch_size=128,epochs=10,\n",
    "          validation_split=0.3,callbacks=[EarlyStopping(monitor='val_loss',min_delta=0.0001)])\n",
    "test_sequences = tok.texts_to_sequences(X1_test)\n",
    "test_sequences_matrix = sequence.pad_sequences(test_sequences,maxlen=max_len)\n",
    "#accr = model.evaluate(test_sequences_matrix,y1_test)\n",
    "loss, accuracy, f1_score, precision, recall = model.evaluate(test_sequences_matrix, y1_test, verbose=0)\n",
    "\n",
    "#print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))\n",
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}\\n fº {:0.3f}'.format(loss,accuracy,f1_score))\n",
    "\n",
    "\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X, Y1, test_size=0.3, random_state=42)\n",
    "\n",
    "max_words = 1000\n",
    "max_len = 200\n",
    "#tok = Tokenizer(num_words=max_words)\n",
    "#tok.fit_on_texts(X1_train)\n",
    "#sequences = tok.texts_to_sequences(X1_train)\n",
    "sequences_matrix = X1_train\n",
    "model = RNN()\n",
    "model.summary()\n",
    "model.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['acc',f1_m,precision_m, recall_m])\n",
    "model.fit(sequences_matrix,y1_train,batch_size=128,epochs=10,\n",
    "          validation_split=0.3,callbacks=[EarlyStopping(monitor='val_loss',min_delta=0.0001)])\n",
    "#test_sequences = X1_test\n",
    "test_sequences_matrix = X1_test\n",
    "#accr = model.evaluate(test_sequences_matrix,y1_test)\n",
    "loss, accuracy, f1_score, precision, recall = model.evaluate(X1_test, y1_test, verbose=0)\n",
    "\n",
    "#print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))\n",
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}\\n fº {:0.3f}'.format(loss,accuracy,f1_score))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          [(None, 200)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_8 (Embedding)      (None, 200, 100)          100000    \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 256)               25856     \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 206,513\n",
      "Trainable params: 206,513\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 200) for input Tensor(\"inputs_8:0\", shape=(None, 200), dtype=float32), but it was called on an input with incompatible shape (None, 100).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 200) for input Tensor(\"inputs_8:0\", shape=(None, 200), dtype=float32), but it was called on an input with incompatible shape (None, 100).\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 0.5909 - acc: 0.7121 - f1_m: 0.0387 - precision_m: 0.0304 - recall_m: 0.0531WARNING:tensorflow:Model was constructed with shape (None, 200) for input Tensor(\"inputs_8:0\", shape=(None, 200), dtype=float32), but it was called on an input with incompatible shape (None, 100).\n",
      "8/8 [==============================] - 1s 111ms/step - loss: 0.5836 - acc: 0.7155 - f1_m: 0.0477 - precision_m: 0.0423 - recall_m: 0.0589 - val_loss: 0.4628 - val_acc: 0.7705 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.4547 - acc: 0.7778 - f1_m: 0.1804 - precision_m: 0.6583 - recall_m: 0.1082 - val_loss: 0.4117 - val_acc: 0.7971 - val_f1_m: 0.3161 - val_precision_m: 0.6340 - val_recall_m: 0.2126\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 0.3537 - acc: 0.8162 - f1_m: 0.4924 - precision_m: 0.7550 - recall_m: 0.3807 - val_loss: 0.3762 - val_acc: 0.8140 - val_f1_m: 0.5153 - val_precision_m: 0.6798 - val_recall_m: 0.4239\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.2803 - acc: 0.8806 - f1_m: 0.7235 - precision_m: 0.8361 - recall_m: 0.6414 - val_loss: 0.3868 - val_acc: 0.8357 - val_f1_m: 0.6488 - val_precision_m: 0.5742 - val_recall_m: 0.7550\n",
      "Test set\n",
      "  Loss: 0.377\n",
      "  Accuracy: 0.824\n",
      " fº 0.610\n",
      "Model: \"functional_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          [(None, 200)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_9 (Embedding)      (None, 200, 100)          100000    \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 256)               25856     \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 206,513\n",
      "Trainable params: 206,513\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "8/8 [==============================] - 2s 215ms/step - loss: 0.8053 - acc: 0.7518 - f1_m: 0.0584 - precision_m: 0.0536 - recall_m: 0.0643 - val_loss: 0.4940 - val_acc: 0.7705 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.4818 - acc: 0.7653 - f1_m: 0.0903 - precision_m: 0.4286 - recall_m: 0.0553 - val_loss: 0.3870 - val_acc: 0.8213 - val_f1_m: 0.4430 - val_precision_m: 0.8000 - val_recall_m: 0.3332\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.3527 - acc: 0.8422 - f1_m: 0.5573 - precision_m: 0.8020 - recall_m: 0.4813 - val_loss: 0.3346 - val_acc: 0.8285 - val_f1_m: 0.4586 - val_precision_m: 0.7631 - val_recall_m: 0.3359\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 0.2663 - acc: 0.8962 - f1_m: 0.7705 - precision_m: 0.8398 - recall_m: 0.7253 - val_loss: 0.2857 - val_acc: 0.8768 - val_f1_m: 0.6967 - val_precision_m: 0.7128 - val_recall_m: 0.6835\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.2280 - acc: 0.9159 - f1_m: 0.8073 - precision_m: 0.8349 - recall_m: 0.8255 - val_loss: 0.2834 - val_acc: 0.8792 - val_f1_m: 0.6913 - val_precision_m: 0.7393 - val_recall_m: 0.6600\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 0.1765 - acc: 0.9418 - f1_m: 0.8843 - precision_m: 0.8694 - recall_m: 0.9021 - val_loss: 0.2832 - val_acc: 0.8768 - val_f1_m: 0.7010 - val_precision_m: 0.7069 - val_recall_m: 0.7010\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 1s 162ms/step - loss: 0.1444 - acc: 0.9512 - f1_m: 0.9011 - precision_m: 0.8989 - recall_m: 0.9098 - val_loss: 0.2966 - val_acc: 0.8768 - val_f1_m: 0.7120 - val_precision_m: 0.7453 - val_recall_m: 0.6932\n",
      "Test set\n",
      "  Loss: 0.331\n",
      "  Accuracy: 0.848\n",
      " fº 0.640\n"
     ]
    }
   ],
   "source": [
    "# CATEGORY 2\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X_orig, Y2, test_size=0.3, random_state=42)\n",
    "\n",
    "max_words = 1000\n",
    "max_len = 200\n",
    "tok = Tokenizer(num_words=max_words)\n",
    "tok.fit_on_texts(X1_train)\n",
    "sequences = tok.texts_to_sequences(X1_train)\n",
    "sequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len)\n",
    "model = RNN()\n",
    "model.summary()\n",
    "model.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['acc',f1_m,precision_m, recall_m])\n",
    "model.fit(sequences_matrix,y1_train,batch_size=128,epochs=10,\n",
    "          validation_split=0.3,callbacks=[EarlyStopping(monitor='val_loss',min_delta=0.0001)])\n",
    "test_sequences = tok.texts_to_sequences(X1_test)\n",
    "test_sequences_matrix = sequence.pad_sequences(test_sequences,maxlen=max_len)\n",
    "loss, accuracy, f1_score, precision, recall = model.evaluate(test_sequences_matrix, y1_test, verbose=0)\n",
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}\\n fº {:0.3f}'.format(loss,accuracy,f1_score))\n",
    "\n",
    "\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X, Y2, test_size=0.3, random_state=42)\n",
    "\n",
    "max_words = 1000\n",
    "max_len = 200\n",
    "#tok = Tokenizer(num_words=max_words)\n",
    "#tok.fit_on_texts(X1_train)\n",
    "#sequences = tok.texts_to_sequences(X1_train)\n",
    "sequences_matrix = X1_train\n",
    "model = RNN()\n",
    "model.summary()\n",
    "model.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['acc',f1_m,precision_m, recall_m])\n",
    "model.fit(sequences_matrix,y1_train,batch_size=128,epochs=10,\n",
    "          validation_split=0.3,callbacks=[EarlyStopping(monitor='val_loss',min_delta=0.0001)])\n",
    "#test_sequences = X1_test\n",
    "test_sequences_matrix = X1_test\n",
    "loss, accuracy, f1_score, precision, recall = model.evaluate(test_sequences_matrix, y1_test, verbose=0)\n",
    "\n",
    "#print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))\n",
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}\\n fº {:0.3f}'.format(loss,accuracy,f1_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          [(None, 200)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_12 (Embedding)     (None, 200, 100)          100000    \n",
      "_________________________________________________________________\n",
      "lstm_12 (LSTM)               (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 256)               25856     \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 206,513\n",
      "Trainable params: 206,513\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 200) for input Tensor(\"inputs_12:0\", shape=(None, 200), dtype=float32), but it was called on an input with incompatible shape (None, 100).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 200) for input Tensor(\"inputs_12:0\", shape=(None, 200), dtype=float32), but it was called on an input with incompatible shape (None, 100).\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6975 - acc: 0.6075 - f1_m: 0.0495 - precision_m: 0.0472 - recall_m: 0.0521WARNING:tensorflow:Model was constructed with shape (None, 200) for input Tensor(\"inputs_12:0\", shape=(None, 200), dtype=float32), but it was called on an input with incompatible shape (None, 100).\n",
      "8/8 [==============================] - 1s 133ms/step - loss: 0.6975 - acc: 0.6075 - f1_m: 0.0495 - precision_m: 0.0472 - recall_m: 0.0521 - val_loss: 0.6527 - val_acc: 0.6208 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 0.6219 - acc: 0.6272 - f1_m: 0.0401 - precision_m: 0.2500 - recall_m: 0.0221 - val_loss: 0.5954 - val_acc: 0.6498 - val_f1_m: 0.1498 - val_precision_m: 1.0000 - val_recall_m: 0.0811\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 1s 90ms/step - loss: 0.5914 - acc: 0.7632 - f1_m: 0.5286 - precision_m: 0.8035 - recall_m: 0.4397 - val_loss: 0.5566 - val_acc: 0.7657 - val_f1_m: 0.6196 - val_precision_m: 0.8705 - val_recall_m: 0.4866\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 0.4353 - acc: 0.8422 - f1_m: 0.7469 - precision_m: 0.8910 - recall_m: 0.6464 - val_loss: 0.5030 - val_acc: 0.7754 - val_f1_m: 0.6502 - val_precision_m: 0.8836 - val_recall_m: 0.5169\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 1s 88ms/step - loss: 0.3558 - acc: 0.8390 - f1_m: 0.7880 - precision_m: 0.8469 - recall_m: 0.7716 - val_loss: 0.5108 - val_acc: 0.7850 - val_f1_m: 0.6768 - val_precision_m: 0.8714 - val_recall_m: 0.5577\n",
      "Test set\n",
      "  Loss: 0.478\n",
      "  Accuracy: 0.785\n",
      " fº 0.691\n",
      "Model: \"functional_27\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          [(None, 200)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_13 (Embedding)     (None, 200, 100)          100000    \n",
      "_________________________________________________________________\n",
      "lstm_13 (LSTM)               (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 256)               25856     \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 206,513\n",
      "Trainable params: 206,513\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "8/8 [==============================] - 2s 264ms/step - loss: 0.6823 - acc: 0.6241 - f1_m: 0.0538 - precision_m: 0.0676 - recall_m: 0.0446 - val_loss: 0.6347 - val_acc: 0.6232 - val_f1_m: 0.0098 - val_precision_m: 0.2500 - val_recall_m: 0.0050\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 1s 180ms/step - loss: 0.5802 - acc: 0.6791 - f1_m: 0.2819 - precision_m: 0.8583 - recall_m: 0.1903 - val_loss: 0.5212 - val_acc: 0.7488 - val_f1_m: 0.5053 - val_precision_m: 0.9591 - val_recall_m: 0.3449\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 1s 185ms/step - loss: 0.4498 - acc: 0.8204 - f1_m: 0.7241 - precision_m: 0.8925 - recall_m: 0.6438 - val_loss: 0.4373 - val_acc: 0.8092 - val_f1_m: 0.7175 - val_precision_m: 0.7552 - val_recall_m: 0.6857\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 2s 188ms/step - loss: 0.3172 - acc: 0.8764 - f1_m: 0.8241 - precision_m: 0.8732 - recall_m: 0.7895 - val_loss: 0.4250 - val_acc: 0.8092 - val_f1_m: 0.7347 - val_precision_m: 0.7135 - val_recall_m: 0.7623\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 1s 187ms/step - loss: 0.2428 - acc: 0.9055 - f1_m: 0.8762 - precision_m: 0.8844 - recall_m: 0.8733 - val_loss: 0.4321 - val_acc: 0.8333 - val_f1_m: 0.7625 - val_precision_m: 0.8067 - val_recall_m: 0.7318\n",
      "Test set\n",
      "  Loss: 0.400\n",
      "  Accuracy: 0.846\n",
      " fº 0.792\n"
     ]
    }
   ],
   "source": [
    "# CATEGORY 3\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X_orig, Y3, test_size=0.3, random_state=42)\n",
    "\n",
    "max_words = 1000\n",
    "max_len = 200\n",
    "tok = Tokenizer(num_words=max_words)\n",
    "tok.fit_on_texts(X1_train)\n",
    "sequences = tok.texts_to_sequences(X1_train)\n",
    "sequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len)\n",
    "model = RNN()\n",
    "model.summary()\n",
    "model.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['acc',f1_m,precision_m, recall_m])\n",
    "model.fit(sequences_matrix,y1_train,batch_size=128,epochs=10,\n",
    "          validation_split=0.3,callbacks=[EarlyStopping(monitor='val_loss',min_delta=0.0001)])\n",
    "test_sequences = tok.texts_to_sequences(X1_test)\n",
    "test_sequences_matrix = sequence.pad_sequences(test_sequences,maxlen=max_len)\n",
    "loss, accuracy, f1_score, precision, recall = model.evaluate(test_sequences_matrix, y1_test, verbose=0)\n",
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}\\n fº {:0.3f}'.format(loss,accuracy,f1_score))\n",
    "\n",
    "\n",
    "\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X, Y3, test_size=0.3, random_state=42)\n",
    "\n",
    "max_words = 1000\n",
    "max_len = 200\n",
    "#tok = Tokenizer(num_words=max_words)\n",
    "#tok.fit_on_texts(X1_train)\n",
    "#sequences = tok.texts_to_sequences(X1_train)\n",
    "sequences_matrix = X1_train\n",
    "model = RNN()\n",
    "model.summary()\n",
    "model.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['acc',f1_m,precision_m, recall_m])\n",
    "model.fit(sequences_matrix,y1_train,batch_size=128,epochs=10,\n",
    "          validation_split=0.3,callbacks=[EarlyStopping(monitor='val_loss',min_delta=0.0001)])\n",
    "#test_sequences = X1_test\n",
    "test_sequences_matrix = X1_test\n",
    "loss, accuracy, f1_score, precision, recall = model.evaluate(test_sequences_matrix, y1_test, verbose=0)\n",
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}\\n fº {:0.3f}'.format(loss,accuracy,f1_score))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_29\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          [(None, 20)]              0         \n",
      "_________________________________________________________________\n",
      "embedding_14 (Embedding)     (None, 20, 100)           100000    \n",
      "_________________________________________________________________\n",
      "lstm_14 (LSTM)               (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 256)               25856     \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 206,513\n",
      "Trainable params: 206,513\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 20) for input Tensor(\"inputs_14:0\", shape=(None, 20), dtype=float32), but it was called on an input with incompatible shape (None, 100).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 20) for input Tensor(\"inputs_14:0\", shape=(None, 20), dtype=float32), but it was called on an input with incompatible shape (None, 100).\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.6245 - acc: 0.7207 - f1_m: 0.0425 - precision_m: 0.0295 - recall_m: 0.0759WARNING:tensorflow:Model was constructed with shape (None, 20) for input Tensor(\"inputs_14:0\", shape=(None, 20), dtype=float32), but it was called on an input with incompatible shape (None, 100).\n",
      "8/8 [==============================] - 1s 131ms/step - loss: 0.6245 - acc: 0.7207 - f1_m: 0.0425 - precision_m: 0.0295 - recall_m: 0.0759 - val_loss: 0.5516 - val_acc: 0.7609 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.5054 - acc: 0.7601 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 0.5192 - val_acc: 0.7826 - val_f1_m: 0.2017 - val_precision_m: 1.0000 - val_recall_m: 0.1145\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 0.3984 - acc: 0.7996 - f1_m: 0.2875 - precision_m: 0.9886 - recall_m: 0.1881 - val_loss: 0.3982 - val_acc: 0.8285 - val_f1_m: 0.4246 - val_precision_m: 0.9688 - val_recall_m: 0.2749\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 0.2819 - acc: 0.8941 - f1_m: 0.7555 - precision_m: 0.8793 - recall_m: 0.6921 - val_loss: 0.3765 - val_acc: 0.8454 - val_f1_m: 0.6759 - val_precision_m: 0.7722 - val_recall_m: 0.6109\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 0.1973 - acc: 0.9315 - f1_m: 0.8368 - precision_m: 0.8825 - recall_m: 0.8240 - val_loss: 0.4895 - val_acc: 0.8454 - val_f1_m: 0.5908 - val_precision_m: 0.9350 - val_recall_m: 0.4371\n",
      "Test set\n",
      "  Loss: 0.461\n",
      "  Accuracy: 0.844\n",
      " fº 0.570\n",
      "Model: \"functional_31\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          [(None, 20)]              0         \n",
      "_________________________________________________________________\n",
      "embedding_15 (Embedding)     (None, 20, 100)           100000    \n",
      "_________________________________________________________________\n",
      "lstm_15 (LSTM)               (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 256)               25856     \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 206,513\n",
      "Trainable params: 206,513\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/8\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.6171 - acc: 0.7248 - f1_m: 0.0278 - precision_m: 0.0200 - recall_m: 0.0455 - val_loss: 0.4988 - val_acc: 0.7609 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 2/8\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.4129 - acc: 0.7892 - f1_m: 0.2175 - precision_m: 0.6111 - recall_m: 0.1427 - val_loss: 0.3788 - val_acc: 0.8623 - val_f1_m: 0.5991 - val_precision_m: 0.9437 - val_recall_m: 0.4417\n",
      "Epoch 3/8\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.2711 - acc: 0.9055 - f1_m: 0.7706 - precision_m: 0.9184 - recall_m: 0.6823 - val_loss: 0.6029 - val_acc: 0.8285 - val_f1_m: 0.5539 - val_precision_m: 0.8516 - val_recall_m: 0.4141\n",
      "Test set\n",
      "  Loss: 0.608\n",
      "  Accuracy: 0.832\n",
      " fº 0.560\n"
     ]
    }
   ],
   "source": [
    "# CATEGORY 4\n",
    "\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X_orig, Y4, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "tok = Tokenizer(num_words=max_words)\n",
    "tok.fit_on_texts(X1_train)\n",
    "sequences = tok.texts_to_sequences(X1_train)\n",
    "sequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len)\n",
    "model = RNN()\n",
    "model.summary()\n",
    "model.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['acc',f1_m,precision_m, recall_m])\n",
    "model.fit(sequences_matrix,y1_train,batch_size=128,epochs=8,\n",
    "          validation_split=0.3,callbacks=[EarlyStopping(monitor='val_loss',min_delta=0.0001)])\n",
    "test_sequences = tok.texts_to_sequences(X1_test)\n",
    "test_sequences_matrix = sequence.pad_sequences(test_sequences,maxlen=max_len)\n",
    "loss, accuracy, f1_score, precision, recall = model.evaluate(test_sequences_matrix, y1_test, verbose=0)\n",
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}\\n fº {:0.3f}'.format(loss,accuracy,f1_score))\n",
    "\n",
    "\n",
    "\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X, Y4, test_size=0.3, random_state=42)\n",
    "\n",
    "max_words = 1000\n",
    "max_len = 20\n",
    "#tok = Tokenizer(num_words=max_words)\n",
    "#tok.fit_on_texts(X1_train)\n",
    "#sequences = tok.texts_to_sequences(X1_train)\n",
    "sequences_matrix = X1_train\n",
    "model = RNN()\n",
    "model.summary()\n",
    "model.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['acc',f1_m,precision_m, recall_m])\n",
    "model.fit(sequences_matrix,y1_train,batch_size=128,epochs=10,\n",
    "          validation_split=0.3,callbacks=[EarlyStopping(monitor='val_loss',min_delta=0.0001)])\n",
    "#test_sequences = X1_test\n",
    "test_sequences_matrix = X1_test\n",
    "loss, accuracy, f1_score, precision, recall = model.evaluate(test_sequences_matrix, y1_test, verbose=0)\n",
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}\\n fº {:0.3f}'.format(loss,accuracy,f1_score))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1968, 100)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/14\n",
      "44/44 [==============================] - 3s 75ms/step - loss: 0.6873 - accuracy: 0.5251 - val_loss: 0.6795 - val_accuracy: 0.4992\n",
      "Epoch 2/14\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 0.6433 - accuracy: 0.5251 - val_loss: 0.5582 - val_accuracy: 0.4992\n",
      "Epoch 3/14\n",
      "44/44 [==============================] - 1s 26ms/step - loss: 0.4750 - accuracy: 0.6935 - val_loss: 0.4228 - val_accuracy: 0.7868\n",
      "Epoch 4/14\n",
      "44/44 [==============================] - 1s 26ms/step - loss: 0.3929 - accuracy: 0.7996 - val_loss: 0.4447 - val_accuracy: 0.7902\n",
      "Epoch 5/14\n",
      "44/44 [==============================] - 1s 26ms/step - loss: 0.3536 - accuracy: 0.8199 - val_loss: 0.3844 - val_accuracy: 0.8342\n",
      "Epoch 6/14\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 0.3109 - accuracy: 0.8620 - val_loss: 0.3793 - val_accuracy: 0.8342\n",
      "Epoch 7/14\n",
      "44/44 [==============================] - 1s 26ms/step - loss: 0.2874 - accuracy: 0.8794 - val_loss: 0.4218 - val_accuracy: 0.8257\n",
      "Epoch 8/14\n",
      "44/44 [==============================] - 1s 26ms/step - loss: 0.2380 - accuracy: 0.9012 - val_loss: 0.4313 - val_accuracy: 0.8460\n",
      "Epoch 9/14\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 0.2098 - accuracy: 0.9230 - val_loss: 0.4797 - val_accuracy: 0.8409\n",
      "Epoch 10/14\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 0.1841 - accuracy: 0.9354 - val_loss: 0.4913 - val_accuracy: 0.8376\n",
      "Epoch 11/14\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 0.1686 - accuracy: 0.9397 - val_loss: 0.4716 - val_accuracy: 0.8460\n",
      "Epoch 12/14\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 0.1456 - accuracy: 0.9528 - val_loss: 0.6600 - val_accuracy: 0.8342\n",
      "Epoch 13/14\n",
      "44/44 [==============================] - 1s 25ms/step - loss: 0.1437 - accuracy: 0.9513 - val_loss: 0.6182 - val_accuracy: 0.8325\n",
      "Epoch 14/14\n",
      "44/44 [==============================] - 1s 24ms/step - loss: 0.1220 - accuracy: 0.9615 - val_loss: 0.6508 - val_accuracy: 0.8359\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.6508 - accuracy: 0.8359\n",
      "Test Loss: 0.6508162021636963\n",
      "Test Accuracy: 0.8358713984489441\n",
      "Epoch 1/14\n",
      "44/44 [==============================] - 3s 70ms/step - loss: 0.6917 - accuracy: 0.5251 - val_loss: 0.6916 - val_accuracy: 0.4992\n",
      "Epoch 2/14\n",
      "44/44 [==============================] - 1s 30ms/step - loss: 0.6838 - accuracy: 0.5251 - val_loss: 0.6796 - val_accuracy: 0.4992\n",
      "Epoch 3/14\n",
      "44/44 [==============================] - 1s 31ms/step - loss: 0.6486 - accuracy: 0.5345 - val_loss: 0.6120 - val_accuracy: 0.5415\n",
      "Epoch 4/14\n",
      "44/44 [==============================] - 1s 31ms/step - loss: 0.5072 - accuracy: 0.6826 - val_loss: 0.4759 - val_accuracy: 0.7530\n",
      "Epoch 5/14\n",
      "44/44 [==============================] - 1s 31ms/step - loss: 0.3909 - accuracy: 0.8257 - val_loss: 0.4562 - val_accuracy: 0.7394\n",
      "Epoch 6/14\n",
      "44/44 [==============================] - 1s 31ms/step - loss: 0.3361 - accuracy: 0.8417 - val_loss: 0.4624 - val_accuracy: 0.7631\n",
      "Epoch 7/14\n",
      "44/44 [==============================] - 1s 31ms/step - loss: 0.3000 - accuracy: 0.8715 - val_loss: 0.4783 - val_accuracy: 0.7750\n",
      "Epoch 8/14\n",
      "44/44 [==============================] - 1s 31ms/step - loss: 0.2589 - accuracy: 0.8947 - val_loss: 0.5039 - val_accuracy: 0.7800\n",
      "Epoch 9/14\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 0.2244 - accuracy: 0.9085 - val_loss: 0.5342 - val_accuracy: 0.8037\n",
      "Epoch 10/14\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 0.1952 - accuracy: 0.9274 - val_loss: 0.5888 - val_accuracy: 0.7563\n",
      "Epoch 11/14\n",
      "44/44 [==============================] - 1s 31ms/step - loss: 0.1738 - accuracy: 0.9375 - val_loss: 0.5851 - val_accuracy: 0.7902\n",
      "Epoch 12/14\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 0.1569 - accuracy: 0.9412 - val_loss: 0.6344 - val_accuracy: 0.7817\n",
      "Epoch 13/14\n",
      "44/44 [==============================] - 1s 31ms/step - loss: 0.1373 - accuracy: 0.9492 - val_loss: 0.7511 - val_accuracy: 0.7868\n",
      "Epoch 14/14\n",
      "44/44 [==============================] - 1s 31ms/step - loss: 0.1244 - accuracy: 0.9506 - val_loss: 0.7667 - val_accuracy: 0.7902\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.7667 - accuracy: 0.7902\n",
      "Test Loss: 0.7667298316955566\n",
      "Test Accuracy: 0.7901861071586609\n"
     ]
    }
   ],
   "source": [
    "# CATEGORY 1\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X, Y1, test_size=0.3, random_state=42)\n",
    "\n",
    "VOCAB_SIZE=1000\n",
    "\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(\n",
    "        input_dim=1968,\n",
    "        output_dim=64,\n",
    "        # Use masking to handle the variable sequence lengths\n",
    "        mask_zero=True),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(2e-4),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X1_train,y1_train, epochs=14,\n",
    "                    validation_data=(X1_test,y1_test), \n",
    "                    validation_steps=30)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X1_test,y1_test)\n",
    "\n",
    "print('Test Loss: {}'.format(test_loss))\n",
    "print('Test Accuracy: {}'.format(test_acc))\n",
    "\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X_orig, Y1, test_size=0.3, random_state=42)\n",
    "\n",
    "VOCAB_SIZE=1000\n",
    "encoder = tf.keras.layers.experimental.preprocessing.TextVectorization(\n",
    "    max_tokens=VOCAB_SIZE)\n",
    "encoder.adapt(np.asarray(X1_train))\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    encoder,\n",
    "    tf.keras.layers.Embedding(\n",
    "        input_dim=len(encoder.get_vocabulary()),\n",
    "        output_dim=64,\n",
    "        # Use masking to handle the variable sequence lengths\n",
    "        mask_zero=True),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(2e-4),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X1_train,y1_train, epochs=14,\n",
    "                    validation_data=(X1_test,y1_test), \n",
    "                    validation_steps=30)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X1_test,y1_test)\n",
    "\n",
    "print('Test Loss: {}'.format(test_loss))\n",
    "print('Test Accuracy: {}'.format(test_acc))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/14\n",
      "44/44 [==============================] - 3s 57ms/step - loss: 0.6695 - accuracy: 0.7618 - val_loss: 0.6091 - val_accuracy: 0.7868\n",
      "Epoch 2/14\n",
      "44/44 [==============================] - 1s 14ms/step - loss: 0.5122 - accuracy: 0.7618 - val_loss: 0.4479 - val_accuracy: 0.7868\n",
      "Epoch 3/14\n",
      "44/44 [==============================] - 1s 14ms/step - loss: 0.4358 - accuracy: 0.7618 - val_loss: 0.3943 - val_accuracy: 0.7868\n",
      "Epoch 4/14\n",
      "44/44 [==============================] - 1s 14ms/step - loss: 0.3525 - accuracy: 0.7618 - val_loss: 0.3299 - val_accuracy: 0.7868\n",
      "Epoch 5/14\n",
      "44/44 [==============================] - 1s 14ms/step - loss: 0.2789 - accuracy: 0.7959 - val_loss: 0.3037 - val_accuracy: 0.8240\n",
      "Epoch 6/14\n",
      "44/44 [==============================] - 1s 14ms/step - loss: 0.2421 - accuracy: 0.8867 - val_loss: 0.3013 - val_accuracy: 0.8426\n",
      "Epoch 7/14\n",
      "44/44 [==============================] - 1s 14ms/step - loss: 0.2028 - accuracy: 0.9063 - val_loss: 0.3078 - val_accuracy: 0.8545\n",
      "Epoch 8/14\n",
      "44/44 [==============================] - 1s 14ms/step - loss: 0.1783 - accuracy: 0.9332 - val_loss: 0.3242 - val_accuracy: 0.8545\n",
      "Epoch 9/14\n",
      "44/44 [==============================] - 1s 14ms/step - loss: 0.1503 - accuracy: 0.9434 - val_loss: 0.3612 - val_accuracy: 0.8477\n",
      "Epoch 10/14\n",
      "44/44 [==============================] - 1s 14ms/step - loss: 0.1257 - accuracy: 0.9557 - val_loss: 0.4194 - val_accuracy: 0.8494\n",
      "Epoch 11/14\n",
      "44/44 [==============================] - 1s 14ms/step - loss: 0.1118 - accuracy: 0.9630 - val_loss: 0.4511 - val_accuracy: 0.8545\n",
      "Epoch 12/14\n",
      "44/44 [==============================] - 1s 14ms/step - loss: 0.0906 - accuracy: 0.9746 - val_loss: 0.4895 - val_accuracy: 0.8443\n",
      "Epoch 13/14\n",
      "44/44 [==============================] - 1s 14ms/step - loss: 0.0763 - accuracy: 0.9789 - val_loss: 0.5518 - val_accuracy: 0.8494\n",
      "Epoch 14/14\n",
      "44/44 [==============================] - 1s 14ms/step - loss: 0.0777 - accuracy: 0.9789 - val_loss: 0.5808 - val_accuracy: 0.8477\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5808 - accuracy: 0.8477\n",
      "Test Loss: 0.5808340311050415\n",
      "Test Accuracy: 0.8477157354354858\n",
      "Epoch 1/14\n",
      "44/44 [==============================] - 3s 70ms/step - loss: 0.6688 - accuracy: 0.7618 - val_loss: 0.6070 - val_accuracy: 0.7868\n",
      "Epoch 2/14\n",
      "44/44 [==============================] - 1s 30ms/step - loss: 0.5517 - accuracy: 0.7618 - val_loss: 0.4970 - val_accuracy: 0.7868\n",
      "Epoch 3/14\n",
      "44/44 [==============================] - 1s 29ms/step - loss: 0.4983 - accuracy: 0.7618 - val_loss: 0.4454 - val_accuracy: 0.7868\n",
      "Epoch 4/14\n",
      "44/44 [==============================] - 1s 29ms/step - loss: 0.4446 - accuracy: 0.7618 - val_loss: 0.4188 - val_accuracy: 0.7868\n",
      "Epoch 5/14\n",
      "44/44 [==============================] - 1s 29ms/step - loss: 0.3866 - accuracy: 0.7691 - val_loss: 0.3903 - val_accuracy: 0.7986\n",
      "Epoch 6/14\n",
      "44/44 [==============================] - 1s 29ms/step - loss: 0.3297 - accuracy: 0.8039 - val_loss: 0.3651 - val_accuracy: 0.8105\n",
      "Epoch 7/14\n",
      "44/44 [==============================] - 1s 29ms/step - loss: 0.2740 - accuracy: 0.8729 - val_loss: 0.3547 - val_accuracy: 0.8393\n",
      "Epoch 8/14\n",
      "44/44 [==============================] - 1s 30ms/step - loss: 0.2376 - accuracy: 0.8903 - val_loss: 0.3746 - val_accuracy: 0.8325\n",
      "Epoch 9/14\n",
      "44/44 [==============================] - 1s 29ms/step - loss: 0.2154 - accuracy: 0.9165 - val_loss: 0.4188 - val_accuracy: 0.8274\n",
      "Epoch 10/14\n",
      "44/44 [==============================] - 1s 29ms/step - loss: 0.1907 - accuracy: 0.9201 - val_loss: 0.4283 - val_accuracy: 0.8257\n",
      "Epoch 11/14\n",
      "44/44 [==============================] - 1s 29ms/step - loss: 0.1770 - accuracy: 0.9252 - val_loss: 0.3991 - val_accuracy: 0.8342\n",
      "Epoch 12/14\n",
      "44/44 [==============================] - 1s 29ms/step - loss: 0.1608 - accuracy: 0.9412 - val_loss: 0.4342 - val_accuracy: 0.8409\n",
      "Epoch 13/14\n",
      "44/44 [==============================] - 1s 29ms/step - loss: 0.1489 - accuracy: 0.9419 - val_loss: 0.4374 - val_accuracy: 0.8342\n",
      "Epoch 14/14\n",
      "44/44 [==============================] - 1s 29ms/step - loss: 0.1251 - accuracy: 0.9586 - val_loss: 0.4659 - val_accuracy: 0.8342\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4659 - accuracy: 0.8342\n",
      "Test Loss: 0.46585118770599365\n",
      "Test Accuracy: 0.8341793417930603\n"
     ]
    }
   ],
   "source": [
    "# CATEGORY 2\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X, Y2, test_size=0.3, random_state=42)\n",
    "\n",
    "VOCAB_SIZE=1000\n",
    "\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(\n",
    "        input_dim=1968,\n",
    "        output_dim=64,\n",
    "        # Use masking to handle the variable sequence lengths\n",
    "        mask_zero=True),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(2e-4),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X1_train,y1_train, epochs=14,\n",
    "                    validation_data=(X1_test,y1_test), \n",
    "                    validation_steps=30)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X1_test,y1_test)\n",
    "\n",
    "print('Test Loss: {}'.format(test_loss))\n",
    "print('Test Accuracy: {}'.format(test_acc))\n",
    "\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X_orig, Y2, test_size=0.3, random_state=42)\n",
    "\n",
    "VOCAB_SIZE=1000\n",
    "encoder = tf.keras.layers.experimental.preprocessing.TextVectorization(\n",
    "    max_tokens=VOCAB_SIZE)\n",
    "encoder.adapt(np.asarray(X1_train))\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    encoder,\n",
    "    tf.keras.layers.Embedding(\n",
    "        input_dim=len(encoder.get_vocabulary()),\n",
    "        output_dim=64,\n",
    "        # Use masking to handle the variable sequence lengths\n",
    "        mask_zero=True),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(2e-4),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X1_train,y1_train, epochs=14,\n",
    "                    validation_data=(X1_test,y1_test), \n",
    "                    validation_steps=30)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X1_test,y1_test)\n",
    "\n",
    "print('Test Loss: {}'.format(test_loss))\n",
    "print('Test Accuracy: {}'.format(test_acc))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/14\n",
      "44/44 [==============================] - 3s 74ms/step - loss: 0.6830 - accuracy: 0.6209 - val_loss: 0.6729 - val_accuracy: 0.6024\n",
      "Epoch 2/14\n",
      "44/44 [==============================] - 1s 19ms/step - loss: 0.6511 - accuracy: 0.6209 - val_loss: 0.6379 - val_accuracy: 0.6024\n",
      "Epoch 3/14\n",
      "44/44 [==============================] - 1s 20ms/step - loss: 0.5607 - accuracy: 0.6209 - val_loss: 0.5128 - val_accuracy: 0.6024\n",
      "Epoch 4/14\n",
      "44/44 [==============================] - 1s 20ms/step - loss: 0.4488 - accuracy: 0.6899 - val_loss: 0.4718 - val_accuracy: 0.8088\n",
      "Epoch 5/14\n",
      "44/44 [==============================] - 1s 20ms/step - loss: 0.3482 - accuracy: 0.8649 - val_loss: 0.4809 - val_accuracy: 0.8291\n",
      "Epoch 6/14\n",
      "44/44 [==============================] - 1s 20ms/step - loss: 0.2847 - accuracy: 0.8845 - val_loss: 0.4603 - val_accuracy: 0.8460\n",
      "Epoch 7/14\n",
      "44/44 [==============================] - 1s 20ms/step - loss: 0.2387 - accuracy: 0.9070 - val_loss: 0.4646 - val_accuracy: 0.8494\n",
      "Epoch 8/14\n",
      "44/44 [==============================] - 1s 20ms/step - loss: 0.2207 - accuracy: 0.9245 - val_loss: 0.5022 - val_accuracy: 0.8409\n",
      "Epoch 9/14\n",
      "44/44 [==============================] - 1s 20ms/step - loss: 0.1849 - accuracy: 0.9317 - val_loss: 0.5550 - val_accuracy: 0.8443\n",
      "Epoch 10/14\n",
      "44/44 [==============================] - 1s 20ms/step - loss: 0.1541 - accuracy: 0.9455 - val_loss: 0.6088 - val_accuracy: 0.8426\n",
      "Epoch 11/14\n",
      "44/44 [==============================] - 1s 20ms/step - loss: 0.1440 - accuracy: 0.9448 - val_loss: 0.5781 - val_accuracy: 0.8426\n",
      "Epoch 12/14\n",
      "44/44 [==============================] - 1s 20ms/step - loss: 0.1102 - accuracy: 0.9630 - val_loss: 0.6563 - val_accuracy: 0.8393\n",
      "Epoch 13/14\n",
      "44/44 [==============================] - 1s 20ms/step - loss: 0.0941 - accuracy: 0.9680 - val_loss: 0.7057 - val_accuracy: 0.8359\n",
      "Epoch 14/14\n",
      "44/44 [==============================] - 1s 20ms/step - loss: 0.0758 - accuracy: 0.9768 - val_loss: 0.8117 - val_accuracy: 0.8359\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.8117 - accuracy: 0.8359\n",
      "Test Loss: 0.8117201328277588\n",
      "Test Accuracy: 0.8358713984489441\n",
      "Epoch 1/14\n",
      "44/44 [==============================] - 4s 92ms/step - loss: 0.6767 - accuracy: 0.6209 - val_loss: 0.6707 - val_accuracy: 0.6024\n",
      "Epoch 2/14\n",
      "44/44 [==============================] - 1s 29ms/step - loss: 0.6603 - accuracy: 0.6209 - val_loss: 0.6666 - val_accuracy: 0.6024\n",
      "Epoch 3/14\n",
      "44/44 [==============================] - 1s 29ms/step - loss: 0.6433 - accuracy: 0.6209 - val_loss: 0.6324 - val_accuracy: 0.6024\n",
      "Epoch 4/14\n",
      "44/44 [==============================] - 1s 29ms/step - loss: 0.5629 - accuracy: 0.6231 - val_loss: 0.5154 - val_accuracy: 0.6345\n",
      "Epoch 5/14\n",
      "44/44 [==============================] - 1s 30ms/step - loss: 0.4519 - accuracy: 0.7705 - val_loss: 0.4601 - val_accuracy: 0.7970\n",
      "Epoch 6/14\n",
      "44/44 [==============================] - 1s 30ms/step - loss: 0.3563 - accuracy: 0.8337 - val_loss: 0.4585 - val_accuracy: 0.7902\n",
      "Epoch 7/14\n",
      "44/44 [==============================] - 1s 31ms/step - loss: 0.3407 - accuracy: 0.8606 - val_loss: 0.4871 - val_accuracy: 0.7733\n",
      "Epoch 8/14\n",
      "44/44 [==============================] - 1s 31ms/step - loss: 0.3184 - accuracy: 0.8497 - val_loss: 0.4733 - val_accuracy: 0.8020\n",
      "Epoch 9/14\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 0.2687 - accuracy: 0.8816 - val_loss: 0.4990 - val_accuracy: 0.7953\n",
      "Epoch 10/14\n",
      "44/44 [==============================] - 1s 31ms/step - loss: 0.2320 - accuracy: 0.8889 - val_loss: 0.5306 - val_accuracy: 0.7868\n",
      "Epoch 11/14\n",
      "44/44 [==============================] - 1s 30ms/step - loss: 0.2021 - accuracy: 0.8998 - val_loss: 0.5525 - val_accuracy: 0.7834\n",
      "Epoch 12/14\n",
      "44/44 [==============================] - 1s 30ms/step - loss: 0.1975 - accuracy: 0.9230 - val_loss: 0.5481 - val_accuracy: 0.7902\n",
      "Epoch 13/14\n",
      "44/44 [==============================] - 1s 30ms/step - loss: 0.1644 - accuracy: 0.9274 - val_loss: 0.5900 - val_accuracy: 0.7885\n",
      "Epoch 14/14\n",
      "44/44 [==============================] - 1s 31ms/step - loss: 0.1471 - accuracy: 0.9375 - val_loss: 0.6196 - val_accuracy: 0.7766\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.6196 - accuracy: 0.7766\n",
      "Test Loss: 0.6196373701095581\n",
      "Test Accuracy: 0.7766497731208801\n"
     ]
    }
   ],
   "source": [
    "# CATEGORY 3\n",
    "\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X, Y3, test_size=0.3, random_state=42)\n",
    "\n",
    "VOCAB_SIZE=1000\n",
    "\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(\n",
    "        input_dim=1968,\n",
    "        output_dim=64,\n",
    "        # Use masking to handle the variable sequence lengths\n",
    "        mask_zero=True),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(2e-4),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X1_train,y1_train, epochs=14,\n",
    "                    validation_data=(X1_test,y1_test), \n",
    "                    validation_steps=30)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X1_test,y1_test)\n",
    "\n",
    "print('Test Loss: {}'.format(test_loss))\n",
    "print('Test Accuracy: {}'.format(test_acc))\n",
    "\n",
    "\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X_orig, Y3, test_size=0.3, random_state=42)\n",
    "\n",
    "VOCAB_SIZE=1000\n",
    "encoder = tf.keras.layers.experimental.preprocessing.TextVectorization(\n",
    "    max_tokens=VOCAB_SIZE)\n",
    "encoder.adapt(np.asarray(X1_train))\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    encoder,\n",
    "    tf.keras.layers.Embedding(\n",
    "        input_dim=len(encoder.get_vocabulary()),\n",
    "        output_dim=64,\n",
    "        # Use masking to handle the variable sequence lengths\n",
    "        mask_zero=True),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(2e-4),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X1_train,y1_train, epochs=14,\n",
    "                    validation_data=(X1_test,y1_test), \n",
    "                    validation_steps=30)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X1_test,y1_test)\n",
    "\n",
    "print('Test Loss: {}'.format(test_loss))\n",
    "print('Test Accuracy: {}'.format(test_acc))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/14\n",
      "44/44 [==============================] - 3s 73ms/step - loss: 0.6698 - accuracy: 0.7603 - val_loss: 0.6253 - val_accuracy: 0.7394\n",
      "Epoch 2/14\n",
      "44/44 [==============================] - 1s 33ms/step - loss: 0.5572 - accuracy: 0.7603 - val_loss: 0.5521 - val_accuracy: 0.7394\n",
      "Epoch 3/14\n",
      "44/44 [==============================] - 1s 33ms/step - loss: 0.4967 - accuracy: 0.7603 - val_loss: 0.4981 - val_accuracy: 0.7394\n",
      "Epoch 4/14\n",
      "44/44 [==============================] - 1s 33ms/step - loss: 0.4141 - accuracy: 0.7603 - val_loss: 0.3894 - val_accuracy: 0.7394\n",
      "Epoch 5/14\n",
      "44/44 [==============================] - 1s 33ms/step - loss: 0.3075 - accuracy: 0.8562 - val_loss: 0.3088 - val_accuracy: 0.8849\n",
      "Epoch 6/14\n",
      "44/44 [==============================] - 1s 33ms/step - loss: 0.2257 - accuracy: 0.9303 - val_loss: 0.2926 - val_accuracy: 0.8917\n",
      "Epoch 7/14\n",
      "44/44 [==============================] - 1s 33ms/step - loss: 0.1817 - accuracy: 0.9477 - val_loss: 0.2905 - val_accuracy: 0.8934\n",
      "Epoch 8/14\n",
      "44/44 [==============================] - 1s 33ms/step - loss: 0.1526 - accuracy: 0.9550 - val_loss: 0.3030 - val_accuracy: 0.8883\n",
      "Epoch 9/14\n",
      "44/44 [==============================] - 1s 33ms/step - loss: 0.1249 - accuracy: 0.9673 - val_loss: 0.3261 - val_accuracy: 0.8934\n",
      "Epoch 10/14\n",
      "44/44 [==============================] - 1s 33ms/step - loss: 0.1036 - accuracy: 0.9695 - val_loss: 0.3620 - val_accuracy: 0.8917\n",
      "Epoch 11/14\n",
      "44/44 [==============================] - 1s 33ms/step - loss: 0.0870 - accuracy: 0.9731 - val_loss: 0.3854 - val_accuracy: 0.8900\n",
      "Epoch 12/14\n",
      "44/44 [==============================] - 1s 33ms/step - loss: 0.0730 - accuracy: 0.9782 - val_loss: 0.3982 - val_accuracy: 0.8934\n",
      "Epoch 13/14\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 0.0598 - accuracy: 0.9833 - val_loss: 0.4419 - val_accuracy: 0.8917\n",
      "Epoch 14/14\n",
      "44/44 [==============================] - 1s 32ms/step - loss: 0.0642 - accuracy: 0.9826 - val_loss: 0.4042 - val_accuracy: 0.8934\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.4042 - accuracy: 0.8934\n",
      "Test Loss: 0.40420636534690857\n",
      "Test Accuracy: 0.893401026725769\n",
      "Epoch 1/14\n",
      "44/44 [==============================] - 4s 95ms/step - loss: 0.6416 - accuracy: 0.7603 - val_loss: 0.5743 - val_accuracy: 0.7394\n",
      "Epoch 2/14\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.5466 - accuracy: 0.7603 - val_loss: 0.5647 - val_accuracy: 0.7394\n",
      "Epoch 3/14\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.5290 - accuracy: 0.7603 - val_loss: 0.5351 - val_accuracy: 0.7394\n",
      "Epoch 4/14\n",
      "44/44 [==============================] - 2s 50ms/step - loss: 0.4702 - accuracy: 0.7603 - val_loss: 0.4451 - val_accuracy: 0.7394\n",
      "Epoch 5/14\n",
      "44/44 [==============================] - 2s 52ms/step - loss: 0.3589 - accuracy: 0.7662 - val_loss: 0.3849 - val_accuracy: 0.7631\n",
      "Epoch 6/14\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.3008 - accuracy: 0.8613 - val_loss: 0.3729 - val_accuracy: 0.8596\n",
      "Epoch 7/14\n",
      "44/44 [==============================] - 2s 48ms/step - loss: 0.2866 - accuracy: 0.8882 - val_loss: 0.3521 - val_accuracy: 0.8342\n",
      "Epoch 8/14\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.2264 - accuracy: 0.9099 - val_loss: 0.3338 - val_accuracy: 0.8494\n",
      "Epoch 9/14\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.1775 - accuracy: 0.9317 - val_loss: 0.3257 - val_accuracy: 0.8680\n",
      "Epoch 10/14\n",
      "44/44 [==============================] - 2s 50ms/step - loss: 0.1391 - accuracy: 0.9513 - val_loss: 0.3406 - val_accuracy: 0.8714\n",
      "Epoch 11/14\n",
      "44/44 [==============================] - 2s 52ms/step - loss: 0.1141 - accuracy: 0.9528 - val_loss: 0.3520 - val_accuracy: 0.8748\n",
      "Epoch 12/14\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.0948 - accuracy: 0.9630 - val_loss: 0.3861 - val_accuracy: 0.8765\n",
      "Epoch 13/14\n",
      "44/44 [==============================] - 2s 50ms/step - loss: 0.0786 - accuracy: 0.9710 - val_loss: 0.4083 - val_accuracy: 0.8731\n",
      "Epoch 14/14\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.0651 - accuracy: 0.9760 - val_loss: 0.4263 - val_accuracy: 0.8697\n",
      "19/19 [==============================] - 0s 16ms/step - loss: 0.4263 - accuracy: 0.8697\n",
      "Test Loss: 0.426342636346817\n",
      "Test Accuracy: 0.8697123527526855\n"
     ]
    }
   ],
   "source": [
    "# CATEGORY 4\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X, Y4, test_size=0.3, random_state=42)\n",
    "\n",
    "VOCAB_SIZE=1000\n",
    "\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(\n",
    "        input_dim=1968,\n",
    "        output_dim=64,\n",
    "        # Use masking to handle the variable sequence lengths\n",
    "        mask_zero=True),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(2e-4),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X1_train,y1_train, epochs=14,\n",
    "                    validation_data=(X1_test,y1_test), \n",
    "                    validation_steps=30)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X1_test,y1_test)\n",
    "\n",
    "print('Test Loss: {}'.format(test_loss))\n",
    "print('Test Accuracy: {}'.format(test_acc))\n",
    "\n",
    "\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X_orig, Y4, test_size=0.3, random_state=42)\n",
    "\n",
    "VOCAB_SIZE=1000\n",
    "encoder = tf.keras.layers.experimental.preprocessing.TextVectorization(\n",
    "    max_tokens=VOCAB_SIZE)\n",
    "encoder.adapt(np.asarray(X1_train))\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    encoder,\n",
    "    tf.keras.layers.Embedding(\n",
    "        input_dim=len(encoder.get_vocabulary()),\n",
    "        output_dim=64,\n",
    "        # Use masking to handle the variable sequence lengths\n",
    "        mask_zero=True),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(2e-4),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X1_train,y1_train, epochs=14,\n",
    "                    validation_data=(X1_test,y1_test), \n",
    "                    validation_steps=30)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X1_test,y1_test)\n",
    "\n",
    "print('Test Loss: {}'.format(test_loss))\n",
    "print('Test Accuracy: {}'.format(test_acc))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
